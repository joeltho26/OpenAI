{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljoseph26/Documents/Education/Machine_and_Deep_Learning/LLMs/OpenAI/OpenAI/env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.6, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What is the capital of India\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljoseph26/Documents/Education/Machine_and_Deep_Learning/LLMs/OpenAI/OpenAI/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\",huggingfacehub_api_token=huggingface_api_key, model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Can you tell me the capital of Russia?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you i love you i love you i love you i love\n"
     ]
    }
   ],
   "source": [
    "output2 = llm_huggingface.predict(\"Can you write a poem about AI?\")\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Templates\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "demo_template = '''Tell me the capital of {country}'''\n",
    "\n",
    "prompt = PromptTempate(\n",
    "    input_variables=['country'],\n",
    "    template = demo_template\n",
    ")\n",
    "\n",
    "prompt.format(country='India')\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template = \"Please enter the capital of {country}.\"\n",
    ")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "famous_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template = \"Suggest me famous places of {capital}.\"\n",
    ")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimpleSequentialChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "parent_chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "parent_chain.run('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template = \"Please enter the capital of {country}.\"\n",
    ")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt,verbose=True,output_key=['capital'])\n",
    "\n",
    "famous_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template = \"Please enter the capital of {capital}.\"\n",
    ")\n",
    "\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_prompt,verbose=True,output_key=['places'])\n",
    "\n",
    "parent_seq_chain = SequentialChain(chains=[capital_chain,famous_chain],\n",
    "                                   input_variables=[\"country\"],\n",
    "                                   output_variables=[\"capital\",\"places\"]\n",
    "                                   )\n",
    "\n",
    "parent_seq_chain({\"country\": 'India'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "\n",
    "chatllm = ChatOpenAI(temperature=0.6, openai_api_key=openai_api_key, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljoseph26/Documents/Education/Machine_and_Deep_Learning/LLMs/Langchain-chapter4/Langchain-Model-Deployment-Huggingface-Spaces/Langchain-Model-Deployment-HuggingFace-Spaces/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please  tell me a joke.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template + LLM + Output Parsers\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commanseparatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are a helpful assistant. When given an input, \n",
    "you should generate 5 synonym words in a comma separated list'''\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",template),\n",
    "        (\"human\",human_template)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | chatllm | Commanseparatedoutput()\n",
    "chain.invoke({'text':\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
